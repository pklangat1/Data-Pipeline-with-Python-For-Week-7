{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Telecommunications Fraud Detection Using MongoDB and Python"
      ],
      "metadata": {
        "id": "docAP-zeXArU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Background Information"
      ],
      "metadata": {
        "id": "Ci4EhrfmXSMt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Telecommunications companies generate a vast amount of data daily, which can be used to\n",
        "detect fraud. Fraudulent activity can lead to substantial financial losses and damage the\n",
        "company's reputation. With the help of data pipelines, companies can detect fraud before it\n",
        "escalates.\n"
      ],
      "metadata": {
        "id": "ryO0VLmsXT5A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Problem Statement"
      ],
      "metadata": {
        "id": "q-6n-M07XI50"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Telecommunications companies need to detect fraudulent activities such as unauthorized use of\n",
        "premium services or fake billing. Building a data pipeline with MongoDB and Python could help\n",
        "identify suspicious activity by extracting data from billing systems, call logs, and other sources,\n",
        "transforming the data to identify patterns or anomalies, and storing it in MongoDB for further\n",
        "analysis"
      ],
      "metadata": {
        "id": "Kbi_5EkbXM8C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###The Solution"
      ],
      "metadata": {
        "id": "Q6b6P-EPYsTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pymongo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqomV8eeLNNH",
        "outputId": "4a92e649-861f-492d-d98c-5f527e0686ef"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.9/dist-packages (4.3.3)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.9/dist-packages (from pymongo) (2.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import libraries needed\n",
        "\n",
        "import pandas as pd\n",
        "import pymongo\n",
        "import logging\n",
        "import zlib\n",
        "from pprint import pprint\n",
        "import pymongo.bulk\n",
        "import csv\n"
      ],
      "metadata": {
        "id": "Yp1zu4DuYvDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Extraction ...."
      ],
      "metadata": {
        "id": "Xb4-OUpo_G0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraction function\n",
        "def extract_data(csv1, csv2):\n",
        "\n",
        "  \"\"\"\n",
        "    Use the pandas library to read the input CSV files.\n",
        "\t  return 2 dfs\n",
        "  \"\"\"\n",
        "\n",
        "  try:\n",
        "    # Load call log data from CSV file\n",
        "    df_calls = pd.read_csv(csv1)\n",
        "\n",
        "    # Load billing data from CSV file\n",
        "    df_billing = pd.read_csv(csv2)\n",
        "\n",
        "    # Use Python logging module to log errors and activities\n",
        "    logger = logging.getLogger(__name__)\n",
        "    logger.info(\"Data extraction completed.\")\n",
        "\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "\n",
        "  return df_calls, df_billing"
      ],
      "metadata": {
        "id": "DMYctJ4AZFD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_calls, df_billing = extract_data('call_logs.csv','billing_systems.csv')"
      ],
      "metadata": {
        "id": "YpWXPywg-kWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_billing.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaKiQ3YharX1",
        "outputId": "3cefd0bb-1d27-497b-d98a-ddbbe09dd795"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "transaction_id          int64\n",
              "customer_id             int64\n",
              "transaction_amount    float64\n",
              "transaction_date       object\n",
              "transaction_type       object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_calls.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41e2bkdV_QQP",
        "outputId": "be710594-2fa4-4d16-d445-ac31aeb50626"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "call_id             int64\n",
              "caller_number       int64\n",
              "receiver_number     int64\n",
              "call_duration       int64\n",
              "call_type          object\n",
              "call_date          object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Explore nulls\n",
        "df_billing.isnull().sum()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNGw20hp_XMY",
        "outputId": "40f3f2db-d4aa-49e6-f0d3-ac29c869edc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "transaction_id        0\n",
              "customer_id           0\n",
              "transaction_amount    0\n",
              "transaction_date      0\n",
              "transaction_type      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_calls.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xx6mQ_8o_A5O",
        "outputId": "a6d4657f-dc70-487d-efd0-7c885728b9ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "call_id            0\n",
              "caller_number      0\n",
              "receiver_number    0\n",
              "call_duration      0\n",
              "call_type          0\n",
              "call_date          0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Transformation ...."
      ],
      "metadata": {
        "id": "X3Pg3hYA_L5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data cleaning and handling missing values, \n",
        "\n",
        "def transformData(df_calls, df_billing):\n",
        "  \"\"\"\n",
        "    Function takes 2dfs as arguments\n",
        "    Performs data conversion, enriches data by adding duration_minutes column\n",
        "  \"\"\"\n",
        "\n",
        "  try:\n",
        "    ##df_calls\n",
        "    ##Add call_duration in minutes column || convert call_type to category || convert call_date to datetime\n",
        "\n",
        "    df_calls['duration_minutes'] = df_calls['call_duration'] / 60\n",
        "\n",
        "    df_calls['call_type'] = df_calls['call_type'].astype(\"category\")\n",
        "\n",
        "    df_calls['call_date'] = pd.to_datetime(df_calls['call_date'])\n",
        "\n",
        "    ##df_billing\n",
        "    ##Convert transaction type to category || convert transaction date to datetime\n",
        "\n",
        "    df_billing['transaction_type'] = df_billing['transaction_type'].astype(\"category\")\n",
        "\n",
        "    df_billing['transaction_date'] = pd.to_datetime(df_billing['transaction_date'])\n",
        "\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "\n",
        "  return df_calls, df_billing\n"
      ],
      "metadata": {
        "id": "fC7-v1SnAeBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_calls, df_billing = transformData(df_calls, df_billing)"
      ],
      "metadata": {
        "id": "0i2dwE6vBb1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Exploring datasets descriptive statistics\n",
        "##Call logs\n",
        "calls1 = df_calls.groupby('call_type')['caller_number'].count()\n",
        "calls1"
      ],
      "metadata": {
        "id": "HBmo1MvEfg9T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caf75a16-8825-49fb-cea9-d614833717cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "call_type\n",
              "Incoming    2\n",
              "Outgoing    3\n",
              "Name: caller_number, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Average call duration\n",
        "calls2 = df_calls.groupby('call_type')['duration_minutes'].mean()\n",
        "calls2"
      ],
      "metadata": {
        "id": "p1AjUozoibEv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4956e532-72c8-4895-e66b-b204a547ee5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "call_type\n",
              "Incoming    1.25\n",
              "Outgoing    3.00\n",
              "Name: duration_minutes, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Average transaction spend\n",
        "bills1 = df_billing.groupby('transaction_type')['transaction_amount'].mean()\n",
        "bills1"
      ],
      "metadata": {
        "id": "FrGB7IzHjRr3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a8940e9-4a3a-4fab-d699-d0dc383accc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "transaction_type\n",
              "Data         50.0\n",
              "Recharge    550.0\n",
              "Name: transaction_amount, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Average spend per customer...\n",
        "bills2   = df_billing.groupby('customer_id')['transaction_amount'].mean()\n",
        "bills2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYmM-LyOjq7t",
        "outputId": "577edd78-460b-479d-cda5-857183702b80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "customer_id\n",
              "1001     275.0\n",
              "1002     200.0\n",
              "1003    1000.0\n",
              "1004     500.0\n",
              "Name: transaction_amount, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Compression function\n",
        "# \n",
        "def compress_data(data):\n",
        "\n",
        "  \"\"\"\n",
        "  takes a df as argument. Returns compressed df as result\n",
        "  \"\"\"\n",
        "  df_bytes = data.to_json().encode()\n",
        "  # Compress data using zlib\n",
        "  compressed_data = zlib.compress(df_bytes)\n",
        "  return compressed_data"
      ],
      "metadata": {
        "id": "uH26jjjRuj-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Loading ....\n"
      ],
      "metadata": {
        "id": "vaRlj8wkIT4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Load function 1 - Create Index, Load DF no compression [using call_logs.csv]\n",
        "\n",
        "def loadNoCompress(data):\n",
        "\n",
        "  \"\"\"\n",
        "  Function to load data to mongodb without any compression. Takes df as argument \n",
        "  \"\"\"\n",
        "\n",
        "  try:\n",
        "    # Connect to MongoDB\n",
        "    #connection string with connection pooling option\n",
        "    conn = \"mongodb+srv://kmaild2010:Siri2022@cluster0.pbxtwyb.mongodb.net/myFirstDatabase?maxPoolSize=50\"\n",
        "\n",
        "    #Enabling ssl option and write concern acknowledgments\n",
        "    client = pymongo.MongoClient(conn,ssl=True, w=1)\n",
        "\n",
        "    # Select database and collection\n",
        "    db = client[\"call_db\"]\n",
        "    collection = db[\"no_compress\"]\n",
        "    \n",
        "    #Build index\n",
        "    collection.create_index([('call_id', 1)])\n",
        "\n",
        "    # Insert the transformed data into the MongoDB database\n",
        "    result = collection.insert_many(data.to_dict('records'))\n",
        "\n",
        "    # Close the database connection\n",
        "    client.close()\n",
        "  \n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "  \n",
        "  # Use Python logging module to log errors and activities\n",
        "  logger = logging.getLogger(__name__)\n",
        "  logger.info(\"load no compression - completed\")\n",
        "  \n",
        "  return print(\"Below the inserted items: \\n\",result.inserted_ids)"
      ],
      "metadata": {
        "id": "gD_Cnzotqq4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###Load function 2 - Load compressed data [using call_logs.csv]\n",
        "\n",
        "def loadCompress(compressed_data):\n",
        "\n",
        "  \"\"\"\n",
        "  Function to load compressed data to mongodb. Takes compressed df as argument\n",
        "  \"\"\"\n",
        "\n",
        "  try:\n",
        "    # Connect to MongoDB\n",
        "    #connection string with connection pooling option\n",
        "    conn = \"mongodb+srv://kmaild2010:Siri2022@cluster0.pbxtwyb.mongodb.net/myFirstDatabase?maxPoolSize=50\"\n",
        "\n",
        "    #Enabling ssl option\n",
        "    client = pymongo.MongoClient(conn,ssl=True)\n",
        "\n",
        "    # Select database and collection\n",
        "    db = client[\"call_db\"]\n",
        "    collection = db[\"with_compression\"]\n",
        "    \n",
        "\n",
        "    # Insert compressed data into MongoDB collection\n",
        "    collection.insert_one({'data': compressed_data})\n",
        "\n",
        "    # Get the database performance stats\n",
        "    stats = db.command(\"dbStats\")\n",
        "    # Print the stats\n",
        "    print(\"Output of dbStats \\n:\",stats)\n",
        "\n",
        "  \n",
        "    # Close the database connection\n",
        "    client.close()\n",
        "\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "  \n",
        "  # Use Python logging module to log errors and activities\n",
        "  logger = logging.getLogger(__name__)\n",
        "  logger.info(\"load with compression - completed\")\n",
        "  \n"
      ],
      "metadata": {
        "id": "1AfS0Dptu3ql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###Load function 3 -  Bulk insert  [using billing_system csv]\n",
        "##!Both csv files have less than 10 records - bulk insert function not needed \n",
        "\n",
        "def loadBulkInsert(data):\n",
        "\n",
        "  \"\"\"\n",
        "  Function to perform bulk insert into mongodb. Takes df as argument \n",
        "  \"\"\"\n",
        "\n",
        "  try:\n",
        "    # Connect to MongoDB\n",
        "    #connection string with connection pooling option\n",
        "    conn = \"mongodb+srv://kmaild2010:Siri2022@cluster0.pbxtwyb.mongodb.net/myFirstDatabase?maxPoolSize=50\"\n",
        "\n",
        "    #Enabling ssl option\n",
        "    client = pymongo.MongoClient(conn,ssl=True)\n",
        "\n",
        "    # Select database and collection\n",
        "    db = client[\"call_db\"]\n",
        "    collection = db[\"bulk_insert\"]\n",
        "\n",
        "    bulk_operations = []\n",
        "    for doc in data.to_dict('records'):\n",
        "        bulk_operations.append(collection.update_one({'_id': doc['transaction_id']}, {'$set': doc}, upsert=True))\n",
        "    collection.bulk_write(bulk_operations)\n",
        "\n",
        "    # Close the database connection\n",
        "    client.close()\n",
        "\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "  # Use Python logging module to log errors and activities\n",
        "  logger = logging.getLogger(__name__)\n",
        "  logger.info(\"load bulk insert - completed\")\n",
        "  \n"
      ],
      "metadata": {
        "id": "JwgtwDvyvDdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###Load function 4 - aggregation pipeline [using call_logs.csv]\n",
        "\n",
        "def loadAggregate():\n",
        "\n",
        "  \"\"\"\n",
        "  Function to perform data aggregation on contents of mongodb collection\n",
        "  \"\"\"\n",
        "\n",
        "  try:\n",
        "    # Connect to MongoDB\n",
        "    #connection string with connection pooling option\n",
        "    conn = \"mongodb+srv://kmaild2010:Siri2022@cluster0.pbxtwyb.mongodb.net/myFirstDatabase?maxPoolSize=50\"\n",
        "\n",
        "    #Enabling ssl option\n",
        "    client = pymongo.MongoClient(conn,ssl=True)\n",
        "\n",
        "    # Select database and collection\n",
        "    db = client[\"call_db\"]\n",
        "    collection = db[\"no_compress\"]\n",
        "\n",
        "    pipeline = [\n",
        "          {\n",
        "              '$group': {\n",
        "                  '_id': '$caller_number',\n",
        "                  'total_minutes': {'$sum': '$duration_minutes'},\n",
        "                  'count': {'$sum': 1}\n",
        "              }\n",
        "          },\n",
        "          {\n",
        "              '$sort': {'total_minutes': -1}\n",
        "          }\n",
        "      ]\n",
        "    result = collection.aggregate(pipeline)\n",
        "    for doc in result:\n",
        "      print(doc)\n",
        "    \n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "  # Close the database connection\n",
        "  client.close()\n",
        "\n",
        "  # Use Python logging module to log errors and activities\n",
        "  logger = logging.getLogger(__name__)\n",
        "  logger.info(\"load aggregate1 - completed\")\n",
        "  "
      ],
      "metadata": {
        "id": "qkcwh5uSvIKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Pipelines...."
      ],
      "metadata": {
        "id": "ee13WriXkCgo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Pipeline  load1 nocompress\n",
        "\n",
        "def main_1():\n",
        "\n",
        "  \"\"\"\n",
        "  Option 1 of pipeline automation\n",
        "  \"\"\"\n",
        "  #extract  \n",
        "  df_calls, df_billing = extract_data('call_logs.csv','billing_systems.csv')\n",
        "  #transform\n",
        "  df_calls, df_billing = transformData(df_calls, df_billing)\n",
        "  #load\n",
        "  loadNoCompress(df_calls)"
      ],
      "metadata": {
        "id": "9JDvPUpDDYgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pipeline load2 with compress\n",
        "\n",
        "def main_2():\n",
        "\n",
        "  \"\"\"\n",
        "  Option 2 of pipeline automation\n",
        "  \"\"\"\n",
        "  #extract\n",
        "  df_calls, df_billing = extract_data('call_logs.csv','billing_systems.csv')\n",
        "  #transform\n",
        "  df_calls, df_billing = transformData(df_calls, df_billing)\n",
        "  #load\n",
        "  loadCompress(compress_data(df_calls))"
      ],
      "metadata": {
        "id": "wn3b6NkQI7er"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pipeline load4 with aggregation \n",
        "\n",
        "def main_3():\n",
        "\n",
        "  \"\"\"\n",
        "  Option 3 of pipeline automation\n",
        "  \"\"\"\n",
        "  #Do aggregation and print\n",
        "  loadAggregate()\n",
        "\n"
      ],
      "metadata": {
        "id": "k-G_r6_QhANe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Main function\n",
        "\n",
        "option_str=\"\"\"Select an option below [1,2,3]\\\n",
        "  Option 1 - ETL with no data compression\\n\n",
        "  Option 2 - ETL with data compression\\n\n",
        "  Option 3 - Perform data aggregation function\\n\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  #Get user choice\n",
        "  option = input(option_str)\n",
        "\n",
        "  if option == '1':\n",
        "    main_1()\n",
        "  elif option == '2':\n",
        "    main_2()\n",
        "  elif option == '3':\n",
        "    main_3()\n",
        "  else:\n",
        "    print(\"Please choose either option 1, 2 or 3 ...\")\n",
        "    option = input(option_str)\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLng-iPr9K1C",
        "outputId": "3b149081-dbe1-4a93-df84-0045444810f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Select an option below [1,2,3]  Option 1 - ETL with no data compression\n",
            "\n",
            "  Option 2 - ETL with data compression\n",
            "\n",
            "  Option 3 - Perform data aggregation function\n",
            "\n",
            "\n",
            "3\n",
            "{'_id': 733333333, 'total_minutes': 48.0, 'count': 12}\n",
            "{'_id': 722222222, 'total_minutes': 36.0, 'count': 12}\n",
            "{'_id': 712345678, 'total_minutes': 30.0, 'count': 24}\n",
            "{'_id': 700123456, 'total_minutes': 24.0, 'count': 12}\n"
          ]
        }
      ]
    }
  ]
}